<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-09-10T12:32:01+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Digitarium</title><subtitle>Understanding how things work. One little piece at a time.</subtitle><entry><title type="html">Horovod on NVIDIA Jetson</title><link href="http://localhost:4000/horovod-on-nvidia-jetson/" rel="alternate" type="text/html" title="Horovod on NVIDIA Jetson" /><published>2019-06-18T18:31:47+09:00</published><updated>2019-06-18T18:31:47+09:00</updated><id>http://localhost:4000/horovod-on-nvidia-jetson</id><content type="html" xml:base="http://localhost:4000/horovod-on-nvidia-jetson/">&lt;p class=&quot;has-medium-font-size&quot;&gt;
Distributed training with Keras on NVIDIA Jetson TX2 and Xavier
&lt;/p&gt;

&lt;p&gt;Horovod (&lt;a href=&quot;https://github.com/horovod/horovod&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;github&lt;/a&gt;) is a software framework for distributed training of neural networks with Keras, Tensorflow, MxNet or PyTorch. Developed at Uber since 2017 it is still in beta version (latest release is v0.16.4 as of 2019/06/18).&lt;/p&gt;

&lt;p&gt;This is a short report on my setup for using a number of NVIDIA Jetson Developer Kits for distributed training.&lt;/p&gt;

&lt;h3 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h3&gt;

&lt;p&gt;Install on all machines: MPI, NCCL, Tensorflow, Keras, Horovod.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MPI&lt;/strong&gt;
OpenMPI should have been already installed with the Jetpack. It is important to have the same version on all computers. Check with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ mpirun --version&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Horovod&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;libffi6 libffi-dev
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pip &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--user&lt;/span&gt; horovod
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;run-distributed-training&quot;&gt;Run distributed training&lt;/h3&gt;

&lt;p&gt;If installation finished without errors, you are ready to run a test. I used &lt;a rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/horovod/horovod/blob/master/examples/keras_mnist.py&quot; target=&quot;_blank&quot;&gt;Keras MNIST example&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is important to have the script file on the PATH on all machines. If it’s not the case, you can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-x&lt;/code&gt; option to mpirun command to copy environment variable (PATH) to all machines.&lt;/p&gt;

&lt;p&gt;To start training I used the following command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;mpirun &lt;span class=&quot;nt&quot;&gt;-np&lt;/span&gt; 3 &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; localhost:1,jetson1:1,jetson2:1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-mca&lt;/span&gt; btl_tcp_if_include eth0 &lt;span class=&quot;nt&quot;&gt;-x&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;NCCL_SOCKET_IFNAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;eth0 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-bind-to&lt;/span&gt; none &lt;span class=&quot;nt&quot;&gt;-map-by&lt;/span&gt; slot python keras_mnist.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-np 3&lt;/code&gt; tells MPI that I need 3 processes: 3 machines each with 1 GPU: 3 processes in total.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-H localhost:1,jetson1:1,jetson2:1&lt;/code&gt; use 1 GPU on localhost (Xavier in my case), 1 GPU on jetson1 and one on jetson2 host. You must be able to login to these hosts with SSH without password ( &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.ssh/config&lt;/code&gt; can help).&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-mca btl_tcp_if_include eth0&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-x NCCL_SOCKET_IFNAME=eth0&lt;/code&gt; options for using eth0 network interface.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-bind-to none -map-by slot&lt;/code&gt; OpenMPI options.&lt;/p&gt;

&lt;p&gt;Below is the video of running Horovod Keras MNIST sample on the 3 machines.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How fast is parallel training?&lt;/strong&gt; Check my notes below the video.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/WPGue7c2PIU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h3 id=&quot;performance-analysis&quot;&gt;Performance Analysis&lt;/h3&gt;

&lt;p&gt;After training the sample network in parallel, I trained it on Xavier and on TX2 with the same parameters without parallelisation. The only hyper-parameter changed is the learning rate, which is set in the sample code to be larger for parallel training: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lr = 1.0 * hvd.size()&lt;/code&gt;. hvd.size() is the number of MPI processes, which in my case is 3 for parallel training and 1 for one-machine training. I ran training in parallel on 3 machines, on Xavier only and on TX2 only until validation accuracy reached &lt;span style=&quot;color:red&quot;&gt;0.99&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;The graph below shows time and validation accuracy per epoch for each training.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;scalable&quot; src=&quot;/wp-content/uploads/2019/06/training_logs-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Regarding epoch time (seconds per epoch) you can see, that:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;For parallel training one epoch time is about the same as epoch time on TX2 (the slowest type of machine).&lt;/li&gt;
  &lt;li&gt;Epoch time on Xavier is the shortest – about 3 times shorter than on TX2.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;

&lt;p&gt;Though accuracy gain per epoch for parallel training is higher than for training on one machine, one parallel training epoch time is equal to epoch time on the slowest of machines. That is because parallel training is done in a synchronous manner and after each epoch all workers share model weight gradients. That means the process on Xavier finishes one epoch earlier, but have to wait for the other two processes on TX2-s to finish.&lt;/p&gt;

&lt;p&gt;All-in-all, unbalance in performance between machines makes parallel training even slower than on one faster machine – Xavier. That, however, may change if more machines were used in training making accuracy gain per epoch even higher.&lt;/p&gt;

&lt;p&gt;You can learn more about parallel training from this thorough post &lt;a rel=&quot;noopener noreferrer&quot; href=&quot;https://towardsdatascience.com/distributed-tensorflow-using-horovod-6d572f8790c4&quot; target=&quot;_blank&quot;&gt;Distributed TensorFlow using Horovod&lt;/a&gt;.&lt;/p&gt;</content><author><name>Peter Bryzgalov</name></author><category term="data parallelism" /><category term="Horovod" /><category term="Jetson AGX Xavier" /><category term="Jetson TX2" /><category term="Keras" /><category term="machine learning" /><category term="model training" /><category term="Nvidia" /><category term="NVIDIA Jetson" /><category term="Tensorflow" /><summary type="html">Distributed training with Keras on NVIDIA Jetson TX2 and Xavier</summary></entry><entry><title type="html">Cloud GPU providers comparison – more graphs</title><link href="http://localhost:4000/cloud-gpu-providers-more-graphs/" rel="alternate" type="text/html" title="Cloud GPU  providers comparison &amp;#8211; more graphs" /><published>2017-01-18T11:30:14+09:00</published><updated>2017-01-18T11:30:14+09:00</updated><id>http://localhost:4000/cloud-gpu-providers-more-graphs</id><content type="html" xml:base="http://localhost:4000/cloud-gpu-providers-more-graphs/">&lt;p&gt;Continued from &lt;a href=&quot;/cloud-gpu-providers-comparison/&quot;&gt;the previous post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;With the graphs below, you can compare calculation time and cost for a fixed amount of calculations in Floating Point Operations. (FLOPs&lt;sup&gt;&lt;a href=&quot;#notes&quot;&gt;***&lt;/a&gt;&lt;/sup&gt;). Use the buttons above the charts to set calculations amount and the number of machines (virtual or bare metal; they are called nodes) used for calculations.&lt;/p&gt;

&lt;p&gt;Important notice: we assume that a task can be run on multiple computers WITHOUT any slowdown. This means that on N machines the task will finish N times faster. This could be true, for instance, in the case of hyperparameters search when you have multiple independent tasks.&lt;/p&gt;

&lt;p&gt;Graphs are not scaled when parameters change to make points movements clearly visible. To scale charts manually use “Autoscale” and “Reset axes” buttons that appear in the top right corner of the graphs when you bring the mouse cursor over it (on tablet devices tap the chart).&lt;/p&gt;

&lt;p class=&quot;note&quot; id=&quot;updated&quot;&gt;
  &lt;p&gt;
    &lt;!--more--&gt;
  &lt;/p&gt;

  &lt;div class=&quot;grouptitle&quot;&gt;
    &lt;h3&gt;
      Filter offers in all graphs below using these charts
    &lt;/h3&gt;

    &lt;div style=&quot;float:none;&quot;&gt;
    &lt;/div&gt;

    &lt;div id=&quot;dc_gpu_models&quot;&gt;
      &lt;title&gt;
        Number of offers by GPU model
      &lt;/title&gt;
    &lt;/div&gt;

    &lt;div class=&quot;dc_group&quot;&gt;
      &lt;div id=&quot;dc_gpus&quot;&gt;
        &lt;title&gt;
          Number of GPUs
        &lt;/title&gt;
      &lt;/div&gt;

      &lt;div id=&quot;dc_gpu_perf&quot;&gt;
        &lt;title&gt;
          Total GPU performance (TFlops)
        &lt;/title&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=&quot;dc_group&quot;&gt;
      &lt;div id=&quot;dc_memory&quot;&gt;
        &lt;title&gt;
          Memory (GB)
        &lt;/title&gt;
      &lt;/div&gt;

      &lt;div id=&quot;dc_cpu_perf&quot;&gt;
        &lt;title&gt;
          Total CPU performance (TFlops)
        &lt;/title&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div id=&quot;dc_providers&quot;&gt;
      &lt;title&gt;
        Number of offers by Providers
      &lt;/title&gt;
    &lt;/div&gt;

    &lt;div id=&quot;dc_end&quot;&gt;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;div id=&quot;messages&quot;&gt;
  &lt;/div&gt;

  &lt;div class=&quot;grouptitle&quot;&gt;
    &lt;h3&gt;
      Set calculation task complexity in EFLOPs and nodes number
    &lt;/h3&gt;

    &lt;div class=&quot;buttons&quot;&gt;
      &lt;h4&gt;
        EFLOPs
      &lt;/h4&gt;

      &lt;div id=&quot;FLOPsScale&quot; style=&quot;width: 100%;&quot;&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=&quot;buttons&quot;&gt;
      &lt;h4&gt;
        nodes
      &lt;/h4&gt;

      &lt;div id=&quot;NodesScale&quot; style=&quot;width: 100%;&quot;&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;p&gt;
      The graph below shows calculation time and cost necessary for calculating a task with task complexity set in &lt;span title=&quot;Floating Point Operations * 10e18&quot;&gt;EFLOPs&lt;/span&gt;&lt;sup&gt;&lt;a href=&quot;#notes&quot;&gt;****&lt;/a&gt;&lt;/sup&gt; on GPU(s) provided by each offer.
    &lt;/p&gt;

    &lt;div id=&quot;GPUtime_x_cost&quot; style=&quot;width: 100%; height: 600px;&quot;&gt;
    &lt;/div&gt;

    &lt;div id=&quot;offer_details1&quot; class=&quot;note&quot;&gt;
      &amp;nbsp;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;div class=&quot;grouptitle&quot;&gt;
    &lt;h3&gt;
      Set calculation task complexity in EFLOPs and nodes number
    &lt;/h3&gt;

    &lt;div class=&quot;buttons&quot;&gt;
      &lt;h4&gt;
        EFLOPs
      &lt;/h4&gt;

      &lt;div id=&quot;FLOPsScale_cpu&quot; style=&quot;width: 100%;&quot;&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=&quot;buttons&quot;&gt;
      &lt;h4&gt;
        nodes
      &lt;/h4&gt;

      &lt;div id=&quot;NodesScale_cpu&quot; style=&quot;width: 100%;&quot;&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;p&gt;
      The graph below shows calculation time and cost necessary for calculating a task with the same complexity using only provided CPUs.
    &lt;/p&gt;

    &lt;div id=&quot;CPUtime_x_cost&quot; style=&quot;width: 100%; height: 600px;&quot;&gt;
    &lt;/div&gt;

    &lt;div id=&quot;offer_details2&quot; class=&quot;note&quot;&gt;
      &amp;nbsp;
    &lt;/div&gt;

    &lt;!--div id=&quot;flops_4money&quot; style=&quot;width: 100%; height: 600px;&quot;&gt;&lt;/div--&gt;

    &lt;div class=&quot;note&quot; id=&quot;notes&quot;&gt;
      &lt;p&gt;
        * All sums are in USD. Offers based on other currencies are converted using today's rates from &lt;a href=&quot;http://www.ecb.europa.eu/stats/exchange/eurofxref/html/index.en.html&quot; target=&quot;_blank&quot;&gt;European Central Bank&lt;/a&gt;:
      &lt;/p&gt;

      &lt;div id=&quot;rates&quot;&gt;
      &lt;/div&gt;

      &lt;p&gt;
        All prices do not include taxes.
      &lt;/p&gt;

      &lt;p&gt;
        ** Performance data shows single precision FLOPS for GPUs and single precision FLOPS for CPUs. &lt;b&gt;Beware that performance data is a rough estimate, and actual performance may vary greatly between applications.&lt;/b&gt;
      &lt;/p&gt;

      &lt;p&gt;
        *** Floating Point Operations (not to be confused with Flops &amp;mdash; Floating Point Operations per Second).
      &lt;/p&gt;


        **** EFLOPs = 1 * 10&lt;sup&gt;18&lt;/sup&gt;FLOPs. TFLOPs = 1 * 10&lt;sup&gt;12&lt;/sup&gt;FLOPs.
      &lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;</content><author><name>Peter Bryzgalov</name></author><category term="AMD" /><category term="AWS" /><category term="Cirrascale" /><category term="cloud computing" /><category term="cloud GPU" /><category term="cloud GPU providers" /><category term="cloud providers comparison" /><category term="compare cloud GPUs" /><category term="compare costs" /><category term="compare price" /><category term="comparison" /><category term="cost" /><category term="could providers" /><category term="EC2" /><category term="GPU" /><category term="GPU performance" /><category term="Intel Xeon" /><category term="LeaderTelecom" /><category term="Nvidia" /><category term="Sakura internet" /><category term="Softlayer" /><summary type="html">Continued from the previous post.</summary></entry><entry><title type="html">Cloud GPU providers comparison</title><link href="http://localhost:4000/cloud-gpu-providers-comparison/" rel="alternate" type="text/html" title="Cloud GPU  providers comparison" /><published>2016-11-21T17:11:47+09:00</published><updated>2016-11-21T17:11:47+09:00</updated><id>http://localhost:4000/cloud-gpu-providers-comparison</id><content type="html" xml:base="http://localhost:4000/cloud-gpu-providers-comparison/">&lt;p&gt;There are plenty of cloud GPU offers from many providers. To help you compare some offers from major providers this post provides you with interactive graphs and a details table with significant parameters of cloud GPU offers, such as cost&lt;sup&gt;&lt;a href=&quot;#notes&quot;&gt;*&lt;/a&gt;&lt;/sup&gt;, GPU and CPU performance&lt;sup&gt;&lt;a href=&quot;#notes&quot;&gt;**&lt;/a&gt;&lt;/sup&gt;, memory etc.&lt;/p&gt;

&lt;p&gt;Please find my article on our &lt;a href=&quot;https://stair.center/archives/439&quot; target=&quot;_blank&quot;&gt;STAIR laboratory web site&lt;/a&gt; about why I created these graphs and how to use them.&lt;/p&gt;

&lt;p&gt;The “filter” charts below provide statistical information about offers distribution by some parameters, such as how many offers each provider has. These charts can also be used for filtering offers. Click on a value in any of the graphs to filter out offers with different values. You can select multiple values. All figures and the table below will show data only for the selected offers.&lt;/p&gt;

&lt;p&gt;Please note, that only offers with at least one GPU are mentioned on this page. Some providers, like Google and Amazon, have too many offers to show them all here, so I picked up only some representative ones.&lt;/p&gt;

&lt;p class=&quot;note&quot; id=&quot;updated&quot;&gt;
  &lt;p&gt;
    &lt;!--more--&gt;
  &lt;/p&gt;

  &lt;div class=&quot;grouptitle&quot;&gt;
    &lt;h3&gt;
      Filter offers in all graphs below using these charts
    &lt;/h3&gt;

    &lt;div style=&quot;float:none;&quot;&gt;
    &lt;/div&gt;
    
    &lt;div id=&quot;dc_gpu_models&quot;&gt;
      &lt;title&gt;
        Number of offers by GPU model
      &lt;/title&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;dc_group&quot;&gt;
      &lt;div id=&quot;dc_gpus&quot;&gt;
        &lt;title&gt;
          Number of GPUs
        &lt;/title&gt;
      &lt;/div&gt;
    
      &lt;div id=&quot;dc_gpu_perf&quot;&gt;
        &lt;title&gt;
          Total GPU performance (TFlops)
        &lt;/title&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;dc_group&quot;&gt;
      &lt;div id=&quot;dc_memory&quot;&gt;
        &lt;title&gt;
          Memory (GB)
        &lt;/title&gt;
      &lt;/div&gt;
    
      &lt;div id=&quot;dc_cpu_perf&quot;&gt;
        &lt;title&gt;
          Total CPU performance (TFlops)
        &lt;/title&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div id=&quot;dc_providers&quot;&gt;
      &lt;title&gt;
        Number of offers by Providers
      &lt;/title&gt;
    &lt;/div&gt;
    
    &lt;div id=&quot;dc_end&quot;&gt;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;div id=&quot;messages&quot;&gt;
  &lt;/div&gt;

  &lt;p&gt;
    The graph below shows the theoretical peak CPU and GPU performance&lt;sup&gt;&lt;a href=&quot;#notes&quot;&gt;**&lt;/a&gt;&lt;/sup&gt; in &lt;span title=&quot;Floating Point Operations per Second * 10e+12&quot;&gt;TFlops&lt;/span&gt; for each offer. Hover over offers to display information below the graph. More detailed information can be found in the table at the bottom of the page. Drag across the chart to zoom in. Click on the legend to filter out offers by a provider.
  &lt;/p&gt;

  &lt;div id=&quot;scatter_performance&quot; style=&quot;width: 100%; height: 500px;&quot;&gt;
  &lt;/div&gt;

  &lt;div id=&quot;offer_details1&quot; class=&quot;note&quot;&gt;
    &amp;nbsp;
  &lt;/div&gt;

  &lt;p&gt;
    The below graph shows the rent cost for a period. The X-axis is the rent period, the Y-axis is the rent cost.
  &lt;/p&gt;

  &lt;p&gt;
    All offers are charged in time units: minutes, hours, weeks, months or years. That is why some lines on the graph have steps.  
  &lt;/p&gt;

  &lt;p&gt;
    Click on the graph to select the rental period. All charts below will change to display data for the selected period. You can also set the period with the buttons below. Drag across the graph to zoom in. Click on the legend to filter offers by a provider.
  &lt;/p&gt;

  &lt;div id=&quot;costs_period&quot; style=&quot;width: 100%; height: 550px;&quot;&gt;
  &lt;/div&gt;

  &lt;div id=&quot;offer_details2&quot; class=&quot;note&quot;&gt;
    &amp;nbsp;
  &lt;/div&gt;

  &lt;div class=&quot;grouptitle&quot;&gt;
    &lt;h3&gt;
      Set rent period for below graphs
    &lt;/h3&gt;

    &lt;div class=&quot;buttons&quot;&gt;
      &lt;div class=&quot;button&quot; id=&quot;day&quot; onclick=&quot;displayTime('1 day');&quot;&gt;
        1 day
      &lt;/div&gt;
    
      &lt;div class=&quot;button&quot; id=&quot;week&quot; onclick=&quot;displayTime('7 days');&quot;&gt;
        1 week
      &lt;/div&gt;
    
      &lt;div class=&quot;button&quot; id=&quot;month&quot; onclick=&quot;displayTime('1 month');&quot;&gt;
        1 month
      &lt;/div&gt;
    
      &lt;div class=&quot;button&quot; id=&quot;3months&quot; onclick=&quot;displayTime('3 month');&quot;&gt;
        3 month
      &lt;/div&gt;
    
      &lt;div class=&quot;button&quot; id=&quot;6months&quot; onclick=&quot;displayTime('6 months');&quot;&gt;
        6 months
      &lt;/div&gt;
    
      &lt;div class=&quot;button&quot; id=&quot;9months&quot; onclick=&quot;displayTime('9 month');&quot;&gt;
        9 month
      &lt;/div&gt;
    
      &lt;div class=&quot;button&quot; id=&quot;12months&quot; onclick=&quot;displayTime('1 year');&quot;&gt;
        1 year
      &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;p&gt;
      The below graph shows total costs if rented for given period.
    &lt;/p&gt;
    
    &lt;div id=&quot;slice_cost&quot; style=&quot;width: 100%; height: 500px;&quot;&gt;
    &lt;/div&gt;
    
    &lt;div id=&quot;offer_details3&quot; class=&quot;note&quot;&gt;
      &amp;nbsp;
    &lt;/div&gt;
    
    &lt;p id=&quot;slice_cost_monthly_text&quot;&gt;
      The below graph shows per month costs if rented for &lt;span id=&quot;r_period&quot;&gt;&lt;/span&gt;.
    &lt;/p&gt;
    
    &lt;div id=&quot;slice_cost_monthly&quot; style=&quot;width: 100%; height: 0px;&quot;&gt;
    &lt;/div&gt;
    
    &lt;p&gt;
      The below graph shows the cost per 1 &lt;span title=&quot;Floating Point Operations per Second * 10e+12&quot;&gt;TFlops&lt;/span&gt; of GPU and CPU performance for the selected rental period in logarithmic scale. To change the rental period, use the buttons above or click on the “cost for rent period” graph.
       &lt;/p&gt;
    
    &lt;div id=&quot;slice_cost_perf&quot; style=&quot;width: 100%; height: 500px;&quot;&gt;
    &lt;/div&gt;
    
    &lt;div id=&quot;offer_details4&quot; class=&quot;note&quot;&gt;
      &amp;nbsp;
    &lt;/div&gt;
  &lt;/div&gt;

  &lt;p&gt;
  &lt;/p&gt;

  &lt;h1 class=&quot;tableTitle&quot;&gt;
    Detailed information for selected offers
  &lt;/h1&gt;

  &lt;div id=&quot;table_div&quot;&gt;
  &lt;/div&gt;

  &lt;div class=&quot;note&quot;&gt;
    &lt;p&gt;
      Links:
    &lt;/p&gt;

    &lt;p&gt;
      &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units&quot; target=&quot;_blank&quot;&gt;wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units&lt;/a&gt;&lt;br /&gt; &lt;a href=&quot;https://www-01.ibm.com/common/ssi/cgi-bin/ssialias?htmlfid=POD03117USEN&quot; target=&quot;_blank&quot;&gt;IBM Power System S822LC for HPC&lt;/a&gt;
    &lt;/p&gt;
  &lt;/div&gt;

  &lt;div class=&quot;note&quot; id=&quot;notes&quot;&gt;
    Notes:

    &lt;p&gt;
      * All prices &lt;b&gt;do not include taxes&lt;/b&gt;. All sums are in &lt;b&gt;USD&lt;/b&gt;. Offers based on other currencies are converted using today's rates from
      &lt;a href=&quot;http://www.ecb.europa.eu/stats/exchange/eurofxref/html/index.en.html&quot; target=&quot;_blank&quot;&gt;European Central Bank&lt;/a&gt;:
    &lt;/p&gt;
    
    &lt;div id=&quot;rates&quot; class=&quot;notes_cell&quot;&gt;
    &lt;/div&gt;
    
    &lt;p&gt;
      ** Performance data shows single precision &lt;span title=&quot;Floating Point Operations per Second&quot;&gt;Flops&lt;/span&gt; for GPUs and single precision &lt;span title=&quot;Floating Point Operations per Second&quot;&gt;Flops&lt;/span&gt; for CPUs. &lt;b&gt;Beware that performance data are theoretical peak values and actual performance will be lower and may vary greatly between applications.&lt;/b&gt;
    &lt;/p&gt;
  &lt;/div&gt;

  &lt;p&gt;
    &lt;a href=&quot;/cloud-gpu-providers-more-graphs/&quot;&gt;Even more graphs: compare calculation time and cost for a fixed amount of calculations.&lt;/a&gt;
  &lt;/p&gt;
&lt;/p&gt;</content><author><name>Peter Bryzgalov</name></author><category term="AMD" /><category term="AWS" /><category term="Cirrascale" /><category term="cloud" /><category term="cloud computing" /><category term="cloud GPU" /><category term="cloud GPU providers" /><category term="cloud providers comparison" /><category term="compare cloud GPUs" /><category term="compare costs" /><category term="compare price" /><category term="EC2" /><category term="GPU" /><category term="GPU performance" /><category term="Intel Xeon" /><category term="LeaderTelecom" /><category term="machine learning" /><category term="Nvidia" /><category term="Sakura internet" /><category term="Softlayer" /><summary type="html">There are plenty of cloud GPU offers from many providers. To help you compare some offers from major providers this post provides you with interactive graphs and a details table with significant parameters of cloud GPU offers, such as cost*, GPU and CPU performance**, memory etc.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/wp-content/uploads/2017/04/stair_eyecatch-1-672x280.png" /><media:content medium="image" url="http://localhost:4000/wp-content/uploads/2017/04/stair_eyecatch-1-672x280.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Bash: Expanding variables and commands in text</title><link href="http://localhost:4000/bash-expanding-variables-in-text/" rel="alternate" type="text/html" title="Bash: Expanding variables and commands in text" /><published>2015-10-15T11:54:19+09:00</published><updated>2015-10-15T11:54:19+09:00</updated><id>http://localhost:4000/bash-expanding-variables-in-text</id><content type="html" xml:base="http://localhost:4000/bash-expanding-variables-in-text/">&lt;p&gt;Say you have a text file with variables or commands in it:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Today is $(date).
I have $n things to do.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Store text file contents in a variable and expand variables and commands in the text with:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Init variables&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;25
&lt;span class=&quot;c&quot;&gt;# Store file in a variable&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;EOF&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;EOF&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Expand text (and print it to stdout)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;cat &amp;amp;lt;&amp;amp;lt;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$text&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That’s it! You will see something like:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Today is Thu Oct 15 12:04:56 JST 2015.
You have 25 things to do.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note, that without &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;echo EOF&lt;/code&gt; bash will use first line of text as a limit string for &lt;a href=&quot;http://tldp.org/LDP/abs/html/here-docs.html&quot; target=&quot;_blank&quot;&gt;heredoc&lt;/a&gt;.&lt;/p&gt;</content><author><name>Peter Bryzgalov</name></author><category term="bash" /><category term="expand variables" /><summary type="html">Say you have a text file with variables or commands in it:</summary></entry><entry><title type="html">Docker ecosystem</title><link href="http://localhost:4000/docker-ecosystem/" rel="alternate" type="text/html" title="Docker ecosystem" /><published>2014-09-10T17:00:35+09:00</published><updated>2014-09-10T17:00:35+09:00</updated><id>http://localhost:4000/docker-ecosystem</id><content type="html" xml:base="http://localhost:4000/docker-ecosystem/">&lt;p&gt;This chart depicts a structure of &lt;a title=&quot;Docker&quot; href=&quot;http://https://www.docker.com&quot; target=&quot;_blank&quot;&gt;Docker&lt;/a&gt;-related tools in terms of their functionality. Docker ecosystem is ever changing, so is this chart. I plan to update it more or less regularly. Any suggestions on how to improve it are welcome.&lt;figure id=&quot;attachment_241&quot; aria-describedby=&quot;caption-attachment-241&quot; style=&quot;width: 600px&quot; class=&quot;wp-caption alignnone&quot;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/wp-content/uploads/2014/09/Docker-ecosystem-8.6.1.pdf&quot; target=&quot;_blank&quot;&gt;
  &lt;img class=&quot;alignnone wp-image-258 size-full&quot; src=&quot;/wp-content/uploads/2014/09/Docker-ecosystem-8.6.1.png&quot; alt=&quot;docker-ecosystem-8-6-1&quot; width=&quot;600&quot; height=&quot;559&quot; /&gt;&lt;em&gt;Link to a large PDF file.&lt;/em&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Last update 2016/10/14&lt;/p&gt;

&lt;h2 id=&quot;about-classification&quot;&gt;About classification&lt;/h2&gt;

&lt;h3 id=&quot;service-discovery&quot;&gt;Service discovery&lt;/h3&gt;

&lt;p&gt;Tools for registering and searching information about services provided by applications running in containers (including multi-host applications).&lt;/p&gt;

&lt;h3 id=&quot;orchestration&quot;&gt;Orchestration&lt;/h3&gt;

&lt;p&gt;Tools with main purpose of managing multi-host multi-container applications. Usually help managing multiple containers and network connections between them.&lt;/p&gt;

&lt;h3 id=&quot;automation&quot;&gt;Automation&lt;/h3&gt;

&lt;p&gt;Tools that help :&lt;br /&gt;
a. making containers easier to use,&lt;br /&gt;
b. giving containers new features,&lt;br /&gt;
c. building a service powered by containers.&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;

&lt;p&gt;Tools for monitoring resources used by containers, containers heath- check, monitoring in-container environment.&lt;/p&gt;

&lt;h3 id=&quot;os&quot;&gt;OS&lt;/h3&gt;

&lt;p&gt;Light-weight OS for running containers.&lt;/p&gt;

&lt;h3 id=&quot;networking&quot;&gt;Networking&lt;/h3&gt;

&lt;p&gt;Tools for organising inter-container and host-container communications.&lt;/p&gt;

&lt;h3 id=&quot;data-and-file-systems&quot;&gt;Data and File Systems&lt;/h3&gt;

&lt;p&gt;Tools for managing data in containers and tools that include or control Docker file system plugins.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: Tools’ features presented on the chart are based on what is advertised on the tool web site or on information provided by the tool developers.&lt;/em&gt;&lt;/p&gt;</content><author><name>Peter Bryzgalov</name></author><category term="ahab" /><category term="cAdvisor" /><category term="Centurion" /><category term="chart" /><category term="Consul" /><category term="CoreOS" /><category term="data management" /><category term="Datakit" /><category term="diagram" /><category term="Docker" /><category term="Docker ecosystem" /><category term="docker IAAS" /><category term="Docker Machine" /><category term="Docker swarm" /><category term="ecosystem" /><category term="etcd" /><category term="Flannel" /><category term="fleet" /><category term="geard" /><category term="Helios" /><category term="InfraKit" /><category term="kubernetes" /><category term="Marathon" /><category term="Mesos" /><category term="monitoring" /><category term="networking" /><category term="New Relic" /><category term="Nomad" /><category term="Openshift Origin" /><category term="orchestration" /><category term="OS" /><category term="Panamax" /><category term="powerstrip" /><category term="Project Atomic" /><category term="Prometheus" /><category term="rancher" /><category term="Rancher OS" /><category term="scheme" /><category term="Scout" /><category term="Serf" /><category term="service discovery" /><category term="Shipyard" /><category term="Signal fx" /><category term="Stackato" /><category term="StackEngine" /><category term="SwarmKit" /><category term="Sysdig cloud" /><category term="wagl" /><summary type="html">This chart depicts a structure of Docker-related tools in terms of their functionality. Docker ecosystem is ever changing, so is this chart. I plan to update it more or less regularly. Any suggestions on how to improve it are welcome.</summary></entry><entry><title type="html">Connect VirtualBox VMs</title><link href="http://localhost:4000/connect-virtualbox-vms/" rel="alternate" type="text/html" title="Connect VirtualBox VMs" /><published>2014-06-20T17:01:46+09:00</published><updated>2014-06-20T17:01:46+09:00</updated><id>http://localhost:4000/connect-virtualbox-vms</id><content type="html" xml:base="http://localhost:4000/connect-virtualbox-vms/">&lt;p&gt;Here is a way to set up networking in VirtualBox VMs so, that VMs can see each other and also the Internet.&lt;/p&gt;

&lt;p&gt;For experiment I used VirtualBox 4.3 on Mac OS X 10.9.&lt;/p&gt;

&lt;p&gt;Created two VMs with Ubuntu 14.04.&lt;/p&gt;

&lt;p&gt;You will need two Network adapters – one for communication between VMs, and another for communication with the outer world. On both VMs set similar Network settings:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adapter 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Attached to : NAT&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-medium wp-image-68&quot; src=&quot;/wp-content/uploads/2014/06/set1.png&quot; alt=&quot;set1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can also set Port Forwarding here to be able to access VM from the host. Here I’ve open port 22 for SSH access. I’ll be able to connect with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh -p 2200 user@localhost&lt;/code&gt; from the host.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-medium wp-image-69&quot; src=&quot;/wp-content/uploads/2014/06/set2.png&quot; alt=&quot;set2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adapter 2&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Attached to: Internal Network&lt;/p&gt;

&lt;p&gt;Name: network-name&lt;/p&gt;

&lt;p&gt;Name can be anything, but must be the same on both machines.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-medium wp-image-70&quot; src=&quot;/wp-content/uploads/2014/06/set3.png&quot; alt=&quot;set3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now start you VMs and open a Terminal window. Test with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ip addr s&lt;/code&gt; command that you have these network interfaces: eth0 and eth1.&lt;/p&gt;

&lt;p&gt;Assign a static IP to the interface of Adapter 2 (type “Internal network”). For me it is eth1. The other one should already have IP address, so you can tell which one you need by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ip addr s&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;I used addresses 10.0.1.3 and 10.0.1.5. For subnet mask I used 255.255.255.0 (CIDR 24 ), which means that all addresses 10.0.1.X will belong to my virtual network.&lt;/p&gt;

&lt;p&gt;Set IP address in terminal window:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;ip addr add 10.0.1.3/24 dev eth1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and on the other machine:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;ip addr add 10.0.1.5/24 dev eth1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test that your first machine is visible from the second:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;user@VirtualBox:~$ ip a s
1: lo: &amp;amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: &amp;amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f2:09:aa brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fef2:9aa/64 scope link 
       valid_lft forever preferred_lft forever
3: eth1: &amp;amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:ba:b2:cb brd ff:ff:ff:ff:ff:ff
    inet 10.0.1.5/24 scope global eth1
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:feba:b2cb/64 scope link 
       valid_lft forever preferred_lft forever
user@VirtualBox:~$ ping 10.0.1.3
PING 10.0.1.3 (10.0.1.3) 56(84) bytes of data.
64 bytes from 10.0.1.3: icmp_seq=1 ttl=64 time=0.425 ms
64 bytes from 10.0.1.3: icmp_seq=2 ttl=64 time=0.217 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Peter Bryzgalov</name></author><category term="ip" /><category term="networking" /><category term="virtual machine" /><category term="VirtualBox" /><summary type="html">Here is a way to set up networking in VirtualBox VMs so, that VMs can see each other and also the Internet.</summary></entry><entry><title type="html">Docker network performance</title><link href="http://localhost:4000/docker-network-performance/" rel="alternate" type="text/html" title="Docker network performance" /><published>2014-06-16T14:54:50+09:00</published><updated>2014-06-16T14:54:50+09:00</updated><id>http://localhost:4000/docker-network-performance</id><content type="html" xml:base="http://localhost:4000/docker-network-performance/">&lt;p&gt;Here are some results of testing performance of different &lt;a title=&quot;An open platform for developers and sysadmins&quot; href=&quot;http://docker.com&quot; target=&quot;_blank&quot;&gt;Docker&lt;/a&gt; Inter Container Communication (ICC) techniques.&lt;/p&gt;

&lt;p&gt;Techniques I tested:&lt;/p&gt;

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      iptables
    &lt;/td&gt;
    
    &lt;td&gt;
      Routing settings that give containers externally visible IP address as described here:  &lt;a title=&quot;blog.codeaholics.org/2013/giving-dockerlxc-containers-a-routable-ip-address/&quot; href=&quot;http://blog.codeaholics.org/2013/giving-dockerlxc-containers-a-routable-ip-address/&quot; target=&quot;_blank&quot;&gt;blog.codeaholics.org/2013/giving-dockerlxc-containers-a-routable-ip-address/&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      pipework
    &lt;/td&gt;
    
    &lt;td&gt;
       &lt;a title=&quot;github.com/jpetazzo/pipework&quot; href=&quot;https://github.com/jpetazzo/pipework&quot; target=&quot;_blank&quot;&gt;github.com/jpetazzo/pipework&lt;/a&gt;  – a tool for assigning external IP addresses to containers. It has two modes: using macvlan interface and using veth pairs. I used the second one – veth pairs.
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
       Docker link
    &lt;/td&gt;
    
    &lt;td&gt;
      Docker feature for inter container communication (ICC). It doesn&amp;#8217;t assign containers external IPs. &lt;a title=&quot;docs.docker.com/userguide/dockerlinks/&quot; href=&quot;https://docs.docker.com/userguide/dockerlinks/&quot; target=&quot;_blank&quot;&gt;docs.docker.com/userguide/dockerlinks/&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
       Open vSwitch
    &lt;/td&gt;
    
    &lt;td&gt;
      &lt;a title=&quot;openvswitch.org&quot; href=&quot;http://openvswitch.org&quot; target=&quot;_blank&quot;&gt;openvswitch.org&lt;/a&gt;&lt;br /&gt; Used version 2.1.0 with kernel support.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Tested on Dell Poweredge D320 server with Xeon 1.8GHz, 4GB (1333MHz) RDIMM, 7200RPM SATA HDD&lt;br /&gt;
OS Ubuntu server 12.04.4 LTS&lt;br /&gt;
kernel 3.8.0-39&lt;br /&gt;
Docker version 0.11.&lt;/p&gt;

&lt;p&gt;Network performance was tested with iperf with the following client command:&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt; iperf -c $ServerIP -P 1 -i 1 -p 5001 -f g -t 5&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Performance in Gbit/s, average for one container.&lt;/p&gt;

&lt;p&gt;The following 3 setups was tested:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;One server container and multiple client containers with 1 iperf process in each container.&lt;/li&gt;
  &lt;li&gt;Multiple servers and multiple clients. 1 iperf process in each container.&lt;/li&gt;
  &lt;li&gt;One server container with one iperf server, multiple containers with multiple iperf clients in each container.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;one-server-and-multiple-clients&quot;&gt;One server and multiple clients&lt;/h2&gt;

&lt;p&gt;ICC performance between one container with one iperf server and multiple containers with one iperf client each. Average performance per container in Gbit/s.&lt;/p&gt;

&lt;table style=&quot;color: #484848;&quot;&gt;
  &lt;tr&gt;
    &lt;th class=&quot;lastheader&quot;&gt;
      client containers
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      1
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      2
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      4
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      8
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      16
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      20
    &lt;/th&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      iptables
    &lt;/td&gt;
    
    &lt;td&gt;
      10.0
    &lt;/td&gt;
    
    &lt;td&gt;
      8.0
    &lt;/td&gt;
    
    &lt;td&gt;
      4.2
    &lt;/td&gt;
    
    &lt;td&gt;
      2.1
    &lt;/td&gt;
    
    &lt;td&gt;
      1.0
    &lt;/td&gt;
    
    &lt;td&gt;
      0.8
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      pipework
    &lt;/td&gt;
    
    &lt;td&gt;
      11.6
    &lt;/td&gt;
    
    &lt;td&gt;
      8.3
    &lt;/td&gt;
    
    &lt;td&gt;
      5.1
    &lt;/td&gt;
    
    &lt;td&gt;
      2.7
    &lt;/td&gt;
    
    &lt;td&gt;
      1.4
    &lt;/td&gt;
    
    &lt;td&gt;
      1.0
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      link
    &lt;/td&gt;
    
    &lt;td&gt;
      12.0
    &lt;/td&gt;
    
    &lt;td&gt;
      8.1
    &lt;/td&gt;
    
    &lt;td&gt;
      4.9
    &lt;/td&gt;
    
    &lt;td&gt;
      2.5
    &lt;/td&gt;
    
    &lt;td&gt;
      1.2
    &lt;/td&gt;
    
    &lt;td&gt;
      1.0
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      ovs
    &lt;/td&gt;
    
    &lt;td&gt;
      13.2
    &lt;/td&gt;
    
    &lt;td&gt;
      11.0
    &lt;/td&gt;
    
    &lt;td&gt;
      6.6
    &lt;/td&gt;
    
    &lt;td&gt;
      3.3
    &lt;/td&gt;
    
    &lt;td&gt;
      1.8
    &lt;/td&gt;
    
    &lt;td&gt;
      1.4
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;/wp-content/uploads/2014/06/ICC1-m-1.png&quot;&gt;&lt;img class=&quot;wp-image-18 size-full&quot; src=&quot;/wp-content/uploads/2014/06/ICC1-m-1.png&quot; alt=&quot;1 server multiple clients&quot; /&gt;&lt;/a&gt;
&lt;em&gt;1 server – multiple clients&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;multiple-servers-and-multiple-clients&quot;&gt;Multiple servers and multiple clients&lt;/h2&gt;

&lt;p&gt;ICC between multiple containers each with one iperf server inside, and multiple containers with one iperf client each. Client number &lt;em&gt;i&lt;/em&gt; connects to the server number &lt;em&gt;i (mod n)&lt;/em&gt;, where &lt;em&gt;n&lt;/em&gt; is the number of servers.&lt;br /&gt;
Below are the average performance results in Gbit/s.&lt;/p&gt;

&lt;table style=&quot;color: #484848;&quot;&gt;
  &lt;tr&gt;
    &lt;th&gt;
      servers
    &lt;/th&gt;
    
    &lt;th&gt;
      1
    &lt;/th&gt;
    
    &lt;th&gt;
      2
    &lt;/th&gt;
    
    &lt;th&gt;
      4
    &lt;/th&gt;
    
    &lt;th&gt;
      20
    &lt;/th&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;th class=&quot;lastheader&quot;&gt;
      clients
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      1
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      2
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      4
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      20
    &lt;/th&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      iptables
    &lt;/td&gt;
    
    &lt;td&gt;
      10.0
    &lt;/td&gt;
    
    &lt;td&gt;
      8.3
    &lt;/td&gt;
    
    &lt;td&gt;
      4.3
    &lt;/td&gt;
    
    &lt;td&gt;
      0.8
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      pipework
    &lt;/td&gt;
    
    &lt;td&gt;
      11.6
    &lt;/td&gt;
    
    &lt;td&gt;
      10.0
    &lt;/td&gt;
    
    &lt;td&gt;
      5.5
    &lt;/td&gt;
    
    &lt;td&gt;
      1.3
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      link
    &lt;/td&gt;
    
    &lt;td&gt;
      12.0
    &lt;/td&gt;
    
    &lt;td&gt;
      9.1
    &lt;/td&gt;
    
    &lt;td&gt;
      5.1
    &lt;/td&gt;
    
    &lt;td&gt;
      1.1
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      ovs
    &lt;/td&gt;
    
    &lt;td&gt;
      13.2
    &lt;/td&gt;
    
    &lt;td&gt;
      10.8
    &lt;/td&gt;
    
    &lt;td&gt;
      5.6
    &lt;/td&gt;
    
    &lt;td&gt;
      1.4
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;/wp-content/uploads/2014/06/ICCn-m-1.png&quot;&gt;&lt;img class=&quot;wp-image-19 size-full&quot; src=&quot;/wp-content/uploads/2014/06/ICCn-m-1.png&quot; alt=&quot;ICCn-m-1&quot; /&gt;&lt;/a&gt;
&lt;em&gt;Multiple servers and multiple clients with 1 iperf process inside.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h2 id=&quot;one-server-and-multiple-containers-with-multiple-iperf-clients-inside&quot;&gt;One server and multiple containers with multiple iperf clients inside&lt;/h2&gt;

&lt;p&gt;Average performance per container in Gbit/sec.&lt;br /&gt;
Number of containers x number of iperf clients in one container&lt;/p&gt;

&lt;table&gt;
  &lt;tr&gt;
    &lt;th class=&quot;lastheader&quot;&gt;
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      1 x 1
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      1 x 2
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      1 x 4
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      1 x 16
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      2 x 1
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      4 x 1
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      16 x 1
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      2 x 2
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      4 x 4
    &lt;/th&gt;
    
    &lt;th class=&quot;lastheader&quot;&gt;
      16 x 16
    &lt;/th&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      pipework
    &lt;/td&gt;
    
    &lt;td&gt;
      11.16
    &lt;/td&gt;
    
    &lt;td&gt;
      9.81
    &lt;/td&gt;
    
    &lt;td&gt;
      3.38
    &lt;/td&gt;
    
    &lt;td&gt;
      1.07
    &lt;/td&gt;
    
    &lt;td&gt;
      9.33
    &lt;/td&gt;
    
    &lt;td&gt;
      4.99
    &lt;/td&gt;
    
    &lt;td&gt;
      1.52
    &lt;/td&gt;
    
    &lt;td&gt;
      4.63
    &lt;/td&gt;
    
    &lt;td&gt;
      1.20
    &lt;/td&gt;
    
    &lt;td&gt;
      0.04
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      link
    &lt;/td&gt;
    
    &lt;td&gt;
      12.10
    &lt;/td&gt;
    
    &lt;td&gt;
      7.70
    &lt;/td&gt;
    
    &lt;td&gt;
      3.30
    &lt;/td&gt;
    
    &lt;td&gt;
      0.80
    &lt;/td&gt;
    
    &lt;td&gt;
      8.20
    &lt;/td&gt;
    
    &lt;td&gt;
      4.90
    &lt;/td&gt;
    
    &lt;td&gt;
      1.20
    &lt;/td&gt;
    
    &lt;td&gt;
      4.30
    &lt;/td&gt;
    
    &lt;td&gt;
      1.10
    &lt;/td&gt;
    
    &lt;td&gt;
      0.00
    &lt;/td&gt;
  &lt;/tr&gt;
  
  &lt;tr&gt;
    &lt;td&gt;
      ovs
    &lt;/td&gt;
    
    &lt;td&gt;
      13.06
    &lt;/td&gt;
    
    &lt;td&gt;
      11.14
    &lt;/td&gt;
    
    &lt;td&gt;
      6.36
    &lt;/td&gt;
    
    &lt;td&gt;
      1.54
    &lt;/td&gt;
    
    &lt;td&gt;
      11.24
    &lt;/td&gt;
    
    &lt;td&gt;
      6.63
    &lt;/td&gt;
    
    &lt;td&gt;
      1.99
    &lt;/td&gt;
    
    &lt;td&gt;
      6.40
    &lt;/td&gt;
    
    &lt;td&gt;
      1.50
    &lt;/td&gt;
    
    &lt;td&gt;
      0.06
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;/wp-content/uploads/2014/06/ICC1-n-m.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-45&quot; src=&quot;/wp-content/uploads/2014/06/ICC1-n-m.png&quot; alt=&quot;ICC1-n-m&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Running iperf clients in different containers gives better performance compared with the same number of clients running in one container (compare 1×4 and 4×1).&lt;/p&gt;</content><author><name>Peter Bryzgalov</name></author><category term="communication" /><category term="containers" /><category term="Docker" /><category term="network performance" /><category term="networking" /><summary type="html">Here are some results of testing performance of different Docker Inter Container Communication (ICC) techniques.</summary></entry></feed>